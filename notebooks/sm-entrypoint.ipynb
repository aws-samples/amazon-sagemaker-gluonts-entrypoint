{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<div style='font-size:200%'>Minimalistic example for gluonts entrypoint script</div>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import boto3\n",
    "import sagemaker as sm\n",
    "from sagemaker.mxnet.estimator import MXNet\n",
    "\n",
    "def get_sm_execution_role(region='us-east-1'):\n",
    "    # cf - https://github.com/aws/sagemaker-python-sdk/issues/300\n",
    "    client = boto3.client('iam', region_name=region)\n",
    "    response_roles = client.list_roles(\n",
    "        PathPrefix='/',\n",
    "        # Marker='string',\n",
    "        MaxItems=999\n",
    "    )\n",
    "    for role in response_roles['Roles']:\n",
    "        if role['RoleName'].startswith('AmazonSageMaker-ExecutionRole-'):\n",
    "            #print('Resolved SageMaker IAM Role to: ' + str(role))\n",
    "            return role['Arn']\n",
    "    raise Exception('Could not resolve what should be the SageMaker role to be used')\n",
    "\n",
    "# A few standard SageMaker's stanzas\n",
    "role: str = get_sm_execution_role()\n",
    "sess = sm.Session()\n",
    "region: str = sess.boto_session.region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: BUCKET=vm-hello-world\n",
      "env: PREFIX=gluonts\n"
     ]
    }
   ],
   "source": [
    "# Ensure no trailing '/'.\n",
    "bucket = 'vm-hello-world'\n",
    "prefix = 'gluonts'\n",
    "\n",
    "%set_env BUCKET=$bucket\n",
    "%set_env PREFIX=$prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data\n",
    "\n",
    "Simply upload sample data to S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ../refdata/test/test.jsonl to s3://vm-hello-world/gluonts/test/test.jsonl\n",
      "upload: ../refdata/metadata.json to s3://vm-hello-world/gluonts/metadata.json\n",
      "upload: ../refdata/train/train.jsonl to s3://vm-hello-world/gluonts/train/train.jsonl\n",
      "2020-04-22 12:57:39          0 gluonts/\n",
      "2020-04-22 14:29:42        412 gluonts/metadata.json\n",
      "2020-04-22 14:29:42        230 gluonts/test/test.jsonl\n",
      "2020-04-22 14:29:42        230 gluonts/train/train.jsonl\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive ../refdata/ s3://$BUCKET/$PREFIX/ --storage-class ONEZONE_IA\n",
    "!aws s3 ls --recursive s3://$BUCKET/$PREFIX/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-22 06:42:32 Starting - Starting the training job...\n",
      "2020-04-22 06:42:34 Starting - Launching requested ML instances......\n",
      "2020-04-22 06:43:36 Starting - Preparing the instances for training...\n",
      "2020-04-22 06:44:17 Downloading - Downloading input data...\n",
      "2020-04-22 06:44:58 Training - Training image download completed. Training in progress..\u001b[34m2020-04-22 06:44:59,601 sagemaker-containers INFO     Imported framework sagemaker_mxnet_container.training\u001b[0m\n",
      "\u001b[34m2020-04-22 06:44:59,604 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-04-22 06:44:59,616 sagemaker_mxnet_container.training INFO     MXNet training environment: {'SM_HOSTS': '[\"algo-1\"]', 'SM_NETWORK_INTERFACE_NAME': 'eth0', 'SM_HPS': '{\"algo\":\"gluonts.model.deepar.DeepAREstimator\",\"cardinality\":\"[5]\",\"distr_output\":\"gluonts.distribution.gaussian.GaussianOutput\",\"num_samples\":1000,\"plot_transparent\":0,\"prediction_length\":2,\"trainer\":\"gluonts.trainer.Trainer\",\"trainer.epochs\":2,\"use_feat_static_cat\":\"True\"}', 'SM_USER_ENTRY_POINT': 'entrypoint.py', 'SM_FRAMEWORK_PARAMS': '{}', 'SM_RESOURCE_CONFIG': '{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}', 'SM_INPUT_DATA_CONFIG': '{\"s3_dataset\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}', 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data', 'SM_CHANNELS': '[\"s3_dataset\"]', 'SM_CURRENT_HOST': 'algo-1', 'SM_MODULE_NAME': 'entrypoint', 'SM_LOG_LEVEL': '20', 'SM_FRAMEWORK_MODULE': 'sagemaker_mxnet_container.training:main', 'SM_INPUT_DIR': '/opt/ml/input', 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config', 'SM_OUTPUT_DIR': '/opt/ml/output', 'SM_NUM_CPUS': '2', 'SM_NUM_GPUS': '0', 'SM_MODEL_DIR': '/opt/ml/model', 'SM_MODULE_DIR': 's3://sagemaker-ap-southeast-1-484597657167/mxnet-training-2020-04-22-06-42-43-224/source/sourcedir.tar.gz', 'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"s3_dataset\":\"/opt/ml/input/data/s3_dataset\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_mxnet_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"algo\":\"gluonts.model.deepar.DeepAREstimator\",\"cardinality\":\"[5]\",\"distr_output\":\"gluonts.distribution.gaussian.GaussianOutput\",\"num_samples\":1000,\"plot_transparent\":0,\"prediction_length\":2,\"trainer\":\"gluonts.trainer.Trainer\",\"trainer.epochs\":2,\"use_feat_static_cat\":\"True\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"s3_dataset\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"mxnet-training-2020-04-22-06-42-43-224\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-southeast-1-484597657167/mxnet-training-2020-04-22-06-42-43-224/source/sourcedir.tar.gz\",\"module_name\":\"entrypoint\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"entrypoint.py\"}', 'SM_USER_ARGS': '[\"--algo\",\"gluonts.model.deepar.DeepAREstimator\",\"--cardinality\",\"[5]\",\"--distr_output\",\"gluonts.distribution.gaussian.GaussianOutput\",\"--num_samples\",\"1000\",\"--plot_transparent\",\"0\",\"--prediction_length\",\"2\",\"--trainer\",\"gluonts.trainer.Trainer\",\"--trainer.epochs\",\"2\",\"--use_feat_static_cat\",\"True\"]', 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate', 'SM_CHANNEL_S3_DATASET': '/opt/ml/input/data/s3_dataset', 'SM_HP_PREDICTION_LENGTH': '2', 'SM_HP_PLOT_TRANSPARENT': '0', 'SM_HP_DISTR_OUTPUT': 'gluonts.distribution.gaussian.GaussianOutput', 'SM_HP_CARDINALITY': '[5]', 'SM_HP_USE_FEAT_STATIC_CAT': 'True', 'SM_HP_TRAINER': 'gluonts.trainer.Trainer', 'SM_HP_TRAINER.EPOCHS': '2', 'SM_HP_ALGO': 'gluonts.model.deepar.DeepAREstimator', 'SM_HP_NUM_SAMPLES': '1000'}\u001b[0m\n",
      "\u001b[34m2020-04-22 06:44:59,951 sagemaker-containers INFO     Module entrypoint does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-04-22 06:44:59,951 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-04-22 06:44:59,951 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-04-22 06:44:59,951 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.6 -m pip install -U . -r requirements.txt\u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mCollecting gluonts==0.4.2 (from -r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/98/c8/113009b077ca127308470dcd4851e53a6b4ad905fe61f36f28d22ff3a4a5/gluonts-0.4.2-py3-none-any.whl (323kB)\u001b[0m\n",
      "\u001b[34mCollecting pydantic<1.5.* (from -r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/be/9a/a2d9613a70051615a84df6e9d697aad9787ba978bdeb4ad46c754457b3e1/pydantic-1.4-cp36-cp36m-manylinux2010_x86_64.whl (7.5MB)\u001b[0m\n",
      "\u001b[34mCollecting holidays<0.10,>=0.9 (from gluonts==0.4.2->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/51/2c/5289263b6bb3a1ac51ddfd1f631947e2636ad9ebe8ac5e88ec37bceffc11/holidays-0.9.12.tar.gz (85kB)\u001b[0m\n",
      "\u001b[34mCollecting ujson~=1.35 (from gluonts==0.4.2->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/16/c4/79f3409bc710559015464e5f49b9879430d8f87498ecdc335899732e5377/ujson-1.35.tar.gz (192kB)\u001b[0m\n",
      "\u001b[34mCollecting matplotlib~=3.0 (from gluonts==0.4.2->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/93/4b/52da6b1523d5139d04e02d9e26ceda6146b48f2a4e5d2abfdf1c7bac8c40/matplotlib-3.2.1-cp36-cp36m-manylinux1_x86_64.whl (12.4MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: python-dateutil==2.8.0 in /usr/local/lib/python3.6/site-packages (from gluonts==0.4.2->-r requirements.txt (line 1)) (2.8.0)\u001b[0m\n",
      "\u001b[34mCollecting tqdm~=4.23 (from gluonts==0.4.2->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34m  Downloading https://files.pythonhosted.org/packages/4a/1c/6359be64e8301b84160f6f6f7936bbfaaa5e9a4eab6cbc681db07600b949/tqdm-4.45.0-py2.py3-none-any.whl (60kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: numpy~=1.14 in /usr/local/lib/python3.6/site-packages (from gluonts==0.4.2->-r requirements.txt (line 1)) (1.14.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: boto3~=1.0 in /usr/local/lib/python3.6/site-packages (from gluonts==0.4.2->-r requirements.txt (line 1)) (1.9.176)\u001b[0m\n",
      "\u001b[34mCollecting pandas<0.26,>=0.25 (from gluonts==0.4.2->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/52/3f/f6a428599e0d4497e1595030965b5ba455fd8ade6e977e3c819973c4b41d/pandas-0.25.3-cp36-cp36m-manylinux1_x86_64.whl (10.4MB)\u001b[0m\n",
      "\u001b[34mCollecting dataclasses>=0.6; python_version < \"3.7\" (from pydantic<1.5.*->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/e1/d2/6f02df2616fd4016075f60157c7a0452b38d8f7938ae94343911e0fb0b09/dataclasses-0.7-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/site-packages (from holidays<0.10,>=0.9->gluonts==0.4.2->-r requirements.txt (line 1)) (1.12.0)\u001b[0m\n",
      "\u001b[34mCollecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 (from matplotlib~=3.0->gluonts==0.4.2->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34m  Downloading https://files.pythonhosted.org/packages/8a/bb/488841f56197b13700afd5658fc279a2025a39e22449b7cf29864669b15d/pyparsing-2.4.7-py2.py3-none-any.whl (67kB)\u001b[0m\n",
      "\u001b[34mCollecting cycler>=0.10 (from matplotlib~=3.0->gluonts==0.4.2->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/f7/d2/e07d3ebb2bd7af696440ce7e754c59dd546ffe1bbe732c8ab68b9c834e61/cycler-0.10.0-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[34mCollecting kiwisolver>=1.0.1 (from matplotlib~=3.0->gluonts==0.4.2->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/ae/23/147de658aabbf968324551ea22c0c13a00284c4ef49a77002e91f79657b7/kiwisolver-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (88kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/site-packages (from boto3~=1.0->gluonts==0.4.2->-r requirements.txt (line 1)) (0.2.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: botocore<1.13.0,>=1.12.176 in /usr/local/lib/python3.6/site-packages (from boto3~=1.0->gluonts==0.4.2->-r requirements.txt (line 1)) (1.12.176)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/site-packages (from boto3~=1.0->gluonts==0.4.2->-r requirements.txt (line 1)) (0.9.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/site-packages (from pandas<0.26,>=0.25->gluonts==0.4.2->-r requirements.txt (line 1)) (2019.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: docutils>=0.10 in /usr/local/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.176->boto3~=1.0->gluonts==0.4.2->-r requirements.txt (line 1)) (0.14)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: urllib3<1.26,>=1.20; python_version >= \"3.4\" in /usr/local/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.176->boto3~=1.0->gluonts==0.4.2->-r requirements.txt (line 1)) (1.24.3)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: holidays, dataclasses, pydantic, ujson, pyparsing, cycler, kiwisolver, matplotlib, tqdm, pandas, gluonts, entrypoint\n",
      "  Running setup.py install for holidays: started\n",
      "    Running setup.py install for holidays: finished with status 'done'\n",
      "  Running setup.py install for ujson: started\u001b[0m\n",
      "\u001b[34m    Running setup.py install for ujson: finished with status 'done'\u001b[0m\n",
      "\u001b[34m  Found existing installation: pandas 0.24.1\n",
      "    Uninstalling pandas-0.24.1:\n",
      "      Successfully uninstalled pandas-0.24.1\u001b[0m\n",
      "\u001b[34m  Running setup.py install for entrypoint: started\n",
      "    Running setup.py install for entrypoint: finished with status 'done'\u001b[0m\n",
      "\u001b[34mSuccessfully installed cycler-0.10.0 dataclasses-0.7 entrypoint-1.0.0 gluonts-0.4.2 holidays-0.9.12 kiwisolver-1.2.0 matplotlib-3.2.1 pandas-0.25.3 pydantic-1.4 pyparsing-2.4.7 tqdm-4.45.0 ujson-1.35\u001b[0m\n",
      "\u001b[34mWARNING: You are using pip version 19.1.1, however version 20.0.2 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-04-22 06:45:10,237 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-04-22 06:45:10,251 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"s3_dataset\": \"/opt/ml/input/data/s3_dataset\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_mxnet_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"prediction_length\": 2,\n",
      "        \"plot_transparent\": 0,\n",
      "        \"distr_output\": \"gluonts.distribution.gaussian.GaussianOutput\",\n",
      "        \"cardinality\": \"[5]\",\n",
      "        \"use_feat_static_cat\": \"True\",\n",
      "        \"trainer\": \"gluonts.trainer.Trainer\",\n",
      "        \"trainer.epochs\": 2,\n",
      "        \"algo\": \"gluonts.model.deepar.DeepAREstimator\",\n",
      "        \"num_samples\": 1000\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"s3_dataset\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"mxnet-training-2020-04-22-06-42-43-224\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-ap-southeast-1-484597657167/mxnet-training-2020-04-22-06-42-43-224/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"entrypoint\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 2,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"entrypoint.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"algo\":\"gluonts.model.deepar.DeepAREstimator\",\"cardinality\":\"[5]\",\"distr_output\":\"gluonts.distribution.gaussian.GaussianOutput\",\"num_samples\":1000,\"plot_transparent\":0,\"prediction_length\":2,\"trainer\":\"gluonts.trainer.Trainer\",\"trainer.epochs\":2,\"use_feat_static_cat\":\"True\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=entrypoint.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"s3_dataset\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"s3_dataset\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=entrypoint\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_mxnet_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=2\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-ap-southeast-1-484597657167/mxnet-training-2020-04-22-06-42-43-224/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"s3_dataset\":\"/opt/ml/input/data/s3_dataset\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_mxnet_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"algo\":\"gluonts.model.deepar.DeepAREstimator\",\"cardinality\":\"[5]\",\"distr_output\":\"gluonts.distribution.gaussian.GaussianOutput\",\"num_samples\":1000,\"plot_transparent\":0,\"prediction_length\":2,\"trainer\":\"gluonts.trainer.Trainer\",\"trainer.epochs\":2,\"use_feat_static_cat\":\"True\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"s3_dataset\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"mxnet-training-2020-04-22-06-42-43-224\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-southeast-1-484597657167/mxnet-training-2020-04-22-06-42-43-224/source/sourcedir.tar.gz\",\"module_name\":\"entrypoint\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"entrypoint.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--algo\",\"gluonts.model.deepar.DeepAREstimator\",\"--cardinality\",\"[5]\",\"--distr_output\",\"gluonts.distribution.gaussian.GaussianOutput\",\"--num_samples\",\"1000\",\"--plot_transparent\",\"0\",\"--prediction_length\",\"2\",\"--trainer\",\"gluonts.trainer.Trainer\",\"--trainer.epochs\",\"2\",\"--use_feat_static_cat\",\"True\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_S3_DATASET=/opt/ml/input/data/s3_dataset\u001b[0m\n",
      "\u001b[34mSM_HP_PREDICTION_LENGTH=2\u001b[0m\n",
      "\u001b[34mSM_HP_PLOT_TRANSPARENT=0\u001b[0m\n",
      "\u001b[34mSM_HP_DISTR_OUTPUT=gluonts.distribution.gaussian.GaussianOutput\u001b[0m\n",
      "\u001b[34mSM_HP_CARDINALITY=[5]\u001b[0m\n",
      "\u001b[34mSM_HP_USE_FEAT_STATIC_CAT=True\u001b[0m\n",
      "\u001b[34mSM_HP_TRAINER=gluonts.trainer.Trainer\u001b[0m\n",
      "\u001b[34mSM_HP_TRAINER.EPOCHS=2\u001b[0m\n",
      "\u001b[34mSM_HP_ALGO=gluonts.model.deepar.DeepAREstimator\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_SAMPLES=1000\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/usr/local/bin:/usr/local/lib/python36.zip:/usr/local/lib/python3.6:/usr/local/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.6 -m entrypoint --algo gluonts.model.deepar.DeepAREstimator --cardinality [5] --distr_output gluonts.distribution.gaussian.GaussianOutput --num_samples 1000 --plot_transparent 0 --prediction_length 2 --trainer gluonts.trainer.Trainer --trainer.epochs 2 --use_feat_static_cat True\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mlevel: 0, name: __main__, handlers: []\u001b[0m\n",
      "\u001b[34mlevel: 20, name: root, handlers: [<StreamHandler <stderr> (NOTSET)>]\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:13] [INFO] __main__ CLI args to entrypoint script: ['/opt/ml/code/entrypoint.py', '--algo', 'gluonts.model.deepar.DeepAREstimator', '--cardinality', '[5]', '--distr_output', 'gluonts.distribution.gaussian.GaussianOutput', '--num_samples', '1000', '--plot_transparent', '0', '--prediction_length', '2', '--trainer', 'gluonts.trainer.Trainer', '--trainer.epochs', '2', '--use_feat_static_cat', 'True']\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:13] [INFO] __main__ Loading dataset from /opt/ml/input/data/s3_dataset\u001b[0m\n",
      "\u001b[34m/opt/ml/code/sm_util.py:99: RuntimeWarning: This implementation still ignores cardinality and static features in the metadata\n",
      "  warnings.warn(\"This implementation still ignores cardinality and static features in the metadata\", RuntimeWarning)\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:13] [INFO] root Using CPU\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:13] [INFO] root Using CPU\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:13] [INFO] __main__ Estimator: gluonts.model.deepar._estimator.DeepAREstimator(cardinality=[5], cell_type=\"lstm\", context_length=None, distr_output=gluonts.distribution.gaussian.GaussianOutput(), dropout_rate=0.1, embedding_dimension=None, freq=\"D\", lags_seq=None, num_cells=40, num_layers=2, num_parallel_samples=100, prediction_length=2, scaling=True, time_features=None, trainer=gluonts.trainer._base.Trainer(batch_size=32, clip_gradient=10.0, ctx=None, epochs=2, hybridize=True, init=\"xavier\", learning_rate=0.001, learning_rate_decay_factor=0.5, minimum_learning_rate=5e-05, num_batches_per_epoch=50, patience=10, weight_decay=1e-08), use_feat_dynamic_real=False, use_feat_static_cat=True, use_feat_static_real=False)\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:13] [INFO] __main__ Starting model training.\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:13] [INFO] root Start model training\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:13] [INFO] root Epoch[0] Learning rate is 0.001\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/50 [00:00<?, ?it/s][2020-04-22 06:45:13] [INFO] root Number of parameters in DeepARTrainingNetwork: 26177\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 50/50 [00:01<00:00, 43.05it/s, avg_epoch_loss=7.24]\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:14] [INFO] root Epoch[0] Elapsed time 1.164 seconds\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:14] [INFO] root Epoch[0] Evaluation metric 'epoch_loss'=7.239015\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:14] [INFO] root Epoch[1] Learning rate is 0.001\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/50 [00:00<?, ?it/s]#015100%|██████████| 50/50 [00:00<00:00, 55.59it/s, avg_epoch_loss=6.77]\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:15] [INFO] root Epoch[1] Elapsed time 0.900 seconds\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:15] [INFO] root Epoch[1] Evaluation metric 'epoch_loss'=6.771429\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:15] [INFO] root Loading parameters from best epoch (1)\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:15] [INFO] root Final loss: 6.7714293384552 (occurred at epoch 1)\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:15] [INFO] root End model training\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:15] [WARNING] root Serializing RepresentableBlockPredictor instances does not save the prediction network structure in a backwards-compatible manner. Be careful not to use this method in production.\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:15] [INFO] __main__ Starting model evaluation.\u001b[0m\n",
      "\u001b[34m#015Running evaluation:   0%|          | 0/2 [00:00<?, ?it/s]#015Running evaluation: 100%|██████████| 2/2 [00:01<00:00,  1.27it/s]\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:17] [INFO] __main__ gluonts[metric-MSE]: 61527.154296875\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:17] [INFO] __main__ gluonts[metric-abs_error]: 863.1536865234375\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:17] [INFO] __main__ gluonts[metric-abs_target_sum]: 4500.0\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:17] [INFO] __main__ gluonts[metric-abs_target_mean]: 1125.0\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:17] [INFO] __main__ gluonts[metric-seasonal_error]: 104.0\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:17] [INFO] __main__ gluonts[metric-MASE]: 2.106765539415421\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:17] [INFO] __main__ gluonts[metric-sMAPE]: 1.0758237725156106\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:17] [INFO] __main__ gluonts[metric-MSIS]: 5.475629037426364\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:17] [INFO] __main__ gluonts[metric-QuantileLoss[0.1]]: 174.8591548919678\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:17] [INFO] __main__ gluonts[metric-Coverage[0.1]]: 0.0\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:17] [INFO] __main__ gluonts[metric-QuantileLoss[0.2]]: 474.69190368652346\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:17] [INFO] __main__ gluonts[metric-Coverage[0.2]]: 0.5\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:17] [INFO] __main__ gluonts[metric-QuantileLoss[0.3]]: 675.4958603858947\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:17] [INFO] __main__ gluonts[metric-Coverage[0.3]]: 0.5\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:17] [INFO] __main__ gluonts[metric-QuantileLoss[0.4]]: 804.0502708435059\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:17] [INFO] __main__ gluonts[metric-Coverage[0.4]]: 0.75\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:17] [INFO] __main__ gluonts[metric-QuantileLoss[0.5]]: 863.1536903381348\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:17] [INFO] __main__ gluonts[metric-Coverage[0.5]]: 0.75\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:17] [INFO] __main__ gluonts[metric-QuantileLoss[0.6]]: 833.2157348632812\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:17] [INFO] __main__ gluonts[metric-Coverage[0.6]]: 0.75\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:17] [INFO] __main__ gluonts[metric-QuantileLoss[0.7]]: 736.475227355957\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:17] [INFO] __main__ gluonts[metric-Coverage[0.7]]: 0.75\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:17] [INFO] __main__ gluonts[metric-QuantileLoss[0.8]]: 507.79671630859366\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:17] [INFO] __main__ gluonts[metric-Coverage[0.8]]: 0.75\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:17] [INFO] __main__ gluonts[metric-QuantileLoss[0.9]]: 215.96967773437495\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:17] [INFO] __main__ gluonts[metric-Coverage[0.9]]: 1.0\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:17] [INFO] __main__ gluonts[metric-RMSE]: 248.0466776574018\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:17] [INFO] __main__ gluonts[metric-NRMSE]: 0.22048593569546826\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:17] [INFO] __main__ gluonts[metric-ND]: 0.19181193033854166\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:17] [INFO] __main__ gluonts[metric-wQuantileLoss[0.1]]: 0.03885758997599284\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:17] [INFO] __main__ gluonts[metric-wQuantileLoss[0.2]]: 0.10548708970811632\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:17] [INFO] __main__ gluonts[metric-wQuantileLoss[0.3]]: 0.1501101911968655\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:17] [INFO] __main__ gluonts[metric-wQuantileLoss[0.4]]: 0.17867783796522355\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:17] [INFO] __main__ gluonts[metric-wQuantileLoss[0.5]]: 0.19181193118625217\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:17] [INFO] __main__ gluonts[metric-wQuantileLoss[0.6]]: 0.18515905219184028\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:17] [INFO] __main__ gluonts[metric-wQuantileLoss[0.7]]: 0.16366116163465713\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:17] [INFO] __main__ gluonts[metric-wQuantileLoss[0.8]]: 0.11284371473524303\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:17] [INFO] __main__ gluonts[metric-wQuantileLoss[0.9]]: 0.04799326171874999\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:17] [INFO] __main__ gluonts[metric-mean_wQuantileLoss]: 0.13051131447921566\u001b[0m\n",
      "\u001b[34m[2020-04-22 06:45:17] [INFO] __main__ gluonts[metric-MAE_Coverage]: 0.17222222222222225\u001b[0m\n",
      "\u001b[34m2020-04-22 06:45:17,654 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-04-22 06:45:26 Uploading - Uploading generated training model\n",
      "2020-04-22 06:45:26 Completed - Training job completed\n",
      "Training seconds: 69\n",
      "Billable seconds: 69\n"
     ]
    }
   ],
   "source": [
    "# Equivalent to: python entrypoint.py --s3-dataset s3_dir --distr_output gluonts.distribution.gaussian.GaussianOutput --use_feat_static_cat True --cardinality '[5]' --prediction_length 2 --trainer gluonts.trainer.Trainer --trainer.epochs 2\n",
    "mxnet_estimator = MXNet(\n",
    "                    entry_point='entrypoint.py',\n",
    "                    source_dir='../src',\n",
    "                    role=role,\n",
    "                    train_instance_count=1,\n",
    "                    train_instance_type='ml.m5.large',\n",
    "                    framework_version='1.4.1',\n",
    "                    hyperparameters={\n",
    "                        # Let's start with non-algorithm hyperparameters\n",
    "                        'plot_transparent': 0,   # Whether plot should be transparent or white background\n",
    "                        'num_samples': 1000,     # Number of samples during backtesting.\n",
    "\n",
    "                        # Here, you specify the algorithm to use, such as DeepAR, DeepFactor, DeepState, Transformer,\n",
    "                        # etc. See glounts.model packages for the list of available algorithms.\n",
    "                        #\n",
    "                        # If 'algo' is not specified, then defaults to 'gluonts.model.deepar.DeepAREstimator'.\n",
    "                        'algo': 'gluonts.model.deepar.DeepAREstimator',\n",
    "\n",
    "                        # The remaining here are kwargs to the chosen estimator. For e.g., for DeepAR, consult the\n",
    "                        # documentation for gluonts.model.deepar.DeepAREstimator.\n",
    "                        #\n",
    "                        # There're two types of kwargs hyperparameters:\n",
    "                        # - primitive python types (incl. dictionaries & lists that can be deserialized from JSON).\n",
    "                        #   Note that string \"True\", \"False\", and \"None\" will automatically become True, False, and\n",
    "                        #   None, respectively.\n",
    "                        # - Custom classes, notably Trainer and distribution output.\n",
    "                        #   Note that time_feat is unsupported at this point in time.\n",
    "                        \n",
    "                        # Kwargs: Primitive python types.\n",
    "                        'use_feat_static_cat': 'True',\n",
    "                        'cardinality': '[5]',\n",
    "                        'prediction_length': 2,\n",
    "\n",
    "                        # Kwargs: custom classes.\n",
    "                        # Currently, this is implemented as a whitelist, and notably missing is for kwarg time_feat.\n",
    "\n",
    "                        # Equivalent to DeepAREstimator(..., distr_output=GaussianOutput(), ...)\n",
    "                        'distr_output': 'gluonts.distribution.gaussian.GaussianOutput',\n",
    "\n",
    "                        # Equivalent to DeepAREstimator(..., trainer=Trainer(epochs=2), ...)\n",
    "                        'trainer': 'gluonts.trainer.Trainer',\n",
    "                        'trainer.epochs': 2,\n",
    "                    },\n",
    "                    py_version='py3')\n",
    "\n",
    "mxnet_estimator.fit({'s3_dataset': f's3://{bucket}/{prefix}'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MODEL_S3=s3://sagemaker-ap-southeast-1-484597657167/mxnet-training-2020-04-22-06-42-43-224/output/model.tar.gz\n",
      "env: OUTPUT_S3=s3://sagemaker-ap-southeast-1-484597657167/mxnet-training-2020-04-22-06-42-43-224/output/output.tar.gz\n"
     ]
    }
   ],
   "source": [
    "model_s3 = mxnet_estimator.latest_training_job.describe()['ModelArtifacts']['S3ModelArtifacts']\n",
    "output_s3 = os.path.join(mxnet_estimator.latest_training_job.describe()['OutputDataConfig']['S3OutputPath'], mxnet_estimator.latest_training_job.job_name, 'output/output.tar.gz')\n",
    "model_s3, output_s3\n",
    "%set_env MODEL_S3=$model_s3\n",
    "%set_env OUTPUT_S3=$output_s3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observe training results\n",
    "\n",
    "As in any SageMaker training job, entrypoint script will generate two artifacts in the S3: `model.tar.gz` and `output.tar.gz`.\n",
    "\n",
    "The `model.tar.gz` contains the persisted model that can be used later on for inference.\n",
    "\n",
    "The `output.tar.gz` contains the following:\n",
    "- individual plot of each test timeseries\n",
    "- montage of plots of all test timeseries\n",
    "- backtest evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model artifacts s3://sagemaker-ap-southeast-1-484597657167/mxnet-training-2020-04-22-06-42-43-224/output/model.tar.gz:\n",
      "-rw-r--r--  0 0      0         476 Apr 22 14:45 parameters.json\n",
      "-rw-r--r--  0 0      0         674 Apr 22 14:45 prediction_net-network.json\n",
      "-rw-r--r--  0 0      0          38 Apr 22 14:45 version.json\n",
      "-rw-r--r--  0 0      0        2778 Apr 22 14:45 input_transform.json\n",
      "-rw-r--r--  0 0      0          51 Apr 22 14:45 type.txt\n",
      "-rw-r--r--  0 0      0      105665 Apr 22 14:45 prediction_net-0000.params\n",
      "\n",
      "Output s3://sagemaker-ap-southeast-1-484597657167/mxnet-training-2020-04-22-06-42-43-224/output/output.tar.gz:\n",
      "-rw-r--r--  0 0      0        1000 Apr 22 14:45 item_metrics.csv\n",
      "-rw-r--r--  0 0      0        1332 Apr 22 14:45 agg_metrics.json\n",
      "drwxr-xr-x  0 0      0           0 Apr 22 14:45 plots/\n",
      "-rw-r--r--  0 0      0       61004 Apr 22 14:45 plots/plots.png\n",
      "drwxr-xr-x  0 0      0           0 Apr 22 14:45 plots/single/\n",
      "-rw-r--r--  0 0      0      122084 Apr 22 14:45 plots/single/000.png\n",
      "-rw-r--r--  0 0      0      156681 Apr 22 14:45 plots/single/001.png\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo -e \"\\nModel artifacts $MODEL_S3:\"\n",
    "aws s3 cp $MODEL_S3 - | tar -tzvf -\n",
    "\n",
    "echo -e \"\\nOutput $OUTPUT_S3:\"\n",
    "aws s3 cp $OUTPUT_S3 - | tar -tzvf -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
